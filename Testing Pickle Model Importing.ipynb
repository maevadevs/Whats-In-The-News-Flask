{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "commercial-stopping",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grand-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alpha-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"./models/MultinomialLogisticRegression-TFIDF5000-Best-RandomizedSearch3CV.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-article",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-playlist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vulnerable-algorithm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For pre-processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define Preprocessing function, which will be used by the TFIDF Vectorizer\n",
    "def process_text(text):\n",
    "    \"\"\"Preprocess a given text: \n",
    "        - Lowercase\n",
    "        - Tokenize\n",
    "        - Remove non-needed tokens\n",
    "        - Lemmatize\n",
    "        - Clean\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to lowercase, replace newlines with spaces, strip whitespaces\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Tokenize\n",
    "    word_tokens = word_tokenize(text)\n",
    "    # Convert to a numpy array\n",
    "    word_tokens = np.array(word_tokens)\n",
    "\n",
    "    # Keep only alphabetic characters\n",
    "    is_alpha = list(map(str.isalpha, word_tokens))\n",
    "    word_tokens = word_tokens[is_alpha]\n",
    "\n",
    "    # Remove stopwords\n",
    "    custom_stopwords = [\"said\", \"say\", \"says\"]\n",
    "    stop_words = set(stopwords.words(\"english\") + custom_stopwords)\n",
    "    is_not_stopword = list(map(lambda token: token not in stop_words, word_tokens))\n",
    "    word_tokens = word_tokens[is_not_stopword]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    vectorize_lemmatizer = np.vectorize(lemmatizer.lemmatize)\n",
    "    word_tokens = vectorize_lemmatizer(word_tokens)\n",
    "\n",
    "    # Convert into a setence form\n",
    "    sentence = \" \".join(word_tokens)\n",
    "\n",
    "    # Return final tokenized sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "second-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file, 'rb') as file:\n",
    "    model = joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complimentary-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "    \n",
    "    category_mapping = [\n",
    "        ('arts and entertainment', 0),\n",
    "        ('automobiles', 1),\n",
    "        ('business', 2),\n",
    "        ('climate and environment', 3),\n",
    "        ('energy', 4),\n",
    "        ('finance and economics', 5),\n",
    "        ('food', 6),\n",
    "        ('global healthcare', 7),\n",
    "        ('health and wellness', 8),\n",
    "        ('legal and crimes', 9),\n",
    "        ('life', 10),\n",
    "        ('markets and investments', 11),\n",
    "        ('personal finance', 12),\n",
    "        ('politics', 13),\n",
    "        ('real estate', 14),\n",
    "        ('science and technology', 15),\n",
    "        ('sports', 16),\n",
    "        ('travel and transportation', 17),\n",
    "        ('us', 18),\n",
    "        ('wealth', 19),\n",
    "        ('world', 20)\n",
    "    ]\n",
    "    \n",
    "    predicted_num = model.predict(text)[0]\n",
    "    \n",
    "    for cat, num in category_mapping:\n",
    "        if num == predicted_num:\n",
    "            return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elect-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"\"\"\n",
    "(CNN) â€” Italian police have seized more than 200 pounds of sand, stones and shells stolen from the beaches of Sardinia last year, dishing out fines to dozens of tourists who took them as souvenirs.\n",
    "The items were returned to the beaches they were taken from earlier this week, the Guardia di Finanza -- Italy's finance police -- said in a statement.\n",
    "The Italian island's idyllic white sand is protected, and tourists face hefty fines and even jail time for removing it from local beaches.\n",
    "Police said 41 people had been fined in connection with the spate of sand and shell thefts; the penalties issued range from 500 to 3,000 euros ($600 to $3,650).\n",
    "The seizures -- totaling more than 100 kilograms (220 pounds) -- took place ''despite the significant decrease in the number of tourists on the island the past summer season'' due to the Covid-19 pandemic, the statement said.\n",
    "Police carried out regular checks on departing travelers at the island's Olbia Costa Smeralda Airport, as well as on various e-commerce sites where the sand was being sold, they added.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advance-softball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'travel and transportation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-absorption",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
